version: 0.0.9
jobId: "166"
jobName: Test Pyspark - State mngt iceberg-Miloni
jobType: Source Aligned Data Product
alias: read
discoveryPort:
  name: Test Pyspark - State mngt iceberg-Miloni
inputPorts:
  - alias: daily_weather
    isDynamic: true
    path: s3://byte-etl-externaldemo/weather_data/20230626130122.csv
    optional:
      persistDataFrame: false
      advanceOptions:
        delimiter: ","
      enableDataReconciliation: false
      enforceSchema: false
      connection: S3 with User
      dataSetUrn: urn:dv:dataset:3a0494b4-86e9-430f-afcb-877a0d9bea95
    type: inputDelimited
productState:
  persistDataFrame: false
  catalogType: glue
  enforceSchema: false
  stepName: read
  tableName: s3Source.weather_daily
  warehousePath: s3://bp-spark-sql-library-test-acc/
  catalogName: glue
  type: readDataIceberg
  isStateManagement: true
  sequence: 3
  alias: read
  refreshInterval: None
  retentionVersions: ""
  logicalSchema:
    properties:
      Actual:
        type: STRING
        description: ""
      Predicted:
        type: STRING
        description: ""
  enforceSchemaMethod: ""
  isProfilingEnabled: false
transformation:
  - alias: EMR_PySpark_1
    arguments:
      - s3://byte-etl-externaldemo/weather_data/20230626130122.csv
    pythonFilePath: s3://bp-spark-sql-library-test-acc/custom-jobs/CustomPythonJobWriteIceWithReg.py
    optional:
      pythonEnvTarGZPath: s3://byte-etl-externaldemo/pyspark_serverless_test/pyspark_venv.tar.gz
    type: customPySparkEMRServerless
    sequence: 2
    references:
      - alias: daily_weather
        sqlReference: ""
controlPort:
  dataQualityRules: {}
outputPort:
  subscriptionChannels:
    - channelType: Postgres
      queryType: SQL
