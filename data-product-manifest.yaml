version: 0.0.3
jobId: "360"
jobName: Custom PySpark Extra Conf Miloni
jobType: Source Aligned Data Product
alias: write_to_iceeee
discoveryPort:
  name: Custom PySpark Extra Conf Miloni
inputPorts:
  - alias: Test_Data_Set_1
    isDynamic: true
    path: "##test_date##"
    optional:
      persistDataFrame: false
      advanceOptions:
        delimiter: test
      enableDataReconciliation: false
      enforceSchema: false
      connection: Base S3 Connectivity
      dataSetUrn: urn:dv:dataset:b26a1127-9bc2-42a5-aab7-d64bd20bf714
    type: inputDelimited
productState:
  persistDataFrame: false
  catalogType: glue
  enforceSchema: false
  stepName: write to iceeee
  tableName: sales.weather_123_3212
  warehousePath: s3://bp-spark-sql-library-test-acc/
  catalogName: glue
  type: readDataIceberg
  isStateManagement: true
  sequence: 3
  alias: write_to_iceeee
  refreshInterval: None
  retentionVersions: ""
  logicalSchema: ""
  enforceSchemaMethod: ""
  isProfilingEnabled: false
transformation:
  - alias: EMR_PySpark_1
    arguments:
      - "##test_date##"
    pythonFilePath: sjkfnsjn
    optional:
      sparkExtraConf:
        ab: ab
    type: customPySparkEMRServerless
    sequence: 2
    references:
      - alias: Test_Data_Set_1
        sqlReference: temp
controlPort:
  dataQualityRules: {}
outputPort:
  subscriptionChannels:
    - channelType: Postgres
      queryType: SQL
